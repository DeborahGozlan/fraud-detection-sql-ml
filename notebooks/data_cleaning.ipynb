{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517df384",
   "metadata": {},
   "source": [
    "# Data Cleaning (Silver Layer) — Ad Fraud Project\n",
    "\n",
    "**Goal:** Clean and normalize raw data coming from multiple sources (TalkingData + simulated noise) before feature engineering.\n",
    "\n",
    "**This notebook will:**\n",
    "1) Connect to PostgreSQL using `.env`\n",
    "2) Build *staging* tables in SQL with strong typing + regex:\n",
    "   - validate IPv4, normalize device casing, extract referrer domains, flag bot user agents\n",
    "   - cast timestamps, flag future/ancient times\n",
    "   - deduplicate near-duplicate clicks\n",
    "3) Clean messy emails (Python regex) into `ad_connections_clean`\n",
    "4) Normalize ad categories (Python fuzzy/canonical mapping) into `ads_clean`\n",
    "5) Produce a small data-quality dashboard (counts & rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b42da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports & DB connection\n",
    "# - Uses .env for credentials\n",
    "# - Creates a SQLAlchemy engine\n",
    "# - Helper run_sql() for executing multi-statement SQL safely\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from difflib import get_close_matches\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\") or os.getenv(\"PGUSER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\") or os.getenv(\"PGHOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\") or os.getenv(\"PGPORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or os.getenv(\"PGDATABASE\")\n",
    "\n",
    "if DB_PASSWORD:\n",
    "    DATABASE_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "else:\n",
    "    DATABASE_URL = f\"postgresql+psycopg2://{DB_USER}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "def run_sql(sql: str):\n",
    "    # Execute arbitrary SQL (supporting multiple statements)\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql))\n",
    "\n",
    "# Quick smoke test\n",
    "with engine.connect() as conn:\n",
    "    v = conn.execute(text(\"select version()\")).scalar()\n",
    "print(\"Connected to:\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade08ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Quick inventory of raw tables\n",
    "tables = [\"ads\", \"raw_clicks\", \"ad_connections\", \"ad_performance\"]\n",
    "with engine.connect() as conn:\n",
    "    for t in tables:\n",
    "        try:\n",
    "            c = conn.execute(text(f\"SELECT COUNT(*) FROM {t}\")).scalar()\n",
    "            print(f\"{t:15s} -> {c:,} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"{t:15s} -> missing ({e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df649f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build staging_clicks_clean (Silver)\n",
    "# - Strong typing: cast click_time to TIMESTAMP, ip to INET (already done in raw, but we double-validate)\n",
    "# - Regex rules:\n",
    "#   * validate IPv4 text shape and octet ranges\n",
    "#   * extract referrer domain\n",
    "#   * detect bot user agents\n",
    "# - Flags: invalid_ip_flag, missing_device_flag, future_time_flag, ancient_time_flag\n",
    "# - Normalize device casing and trim\n",
    "\n",
    "sql_staging_clean = \"\"\"\n",
    "-- Create structure (idempotent)\n",
    "DROP TABLE IF EXISTS staging_clicks_clean;\n",
    "CREATE TABLE staging_clicks_clean AS\n",
    "SELECT\n",
    "    rc.ad_id,\n",
    "    -- Validate IPv4, otherwise NULL\n",
    "    CASE\n",
    "        WHEN rc.ip_address::text ~ '^(?:\\\\d{1,3}\\\\.){3}\\\\d{1,3}$'\n",
    "         AND split_part(rc.ip_address::text, '.', 1)::int BETWEEN 0 AND 255\n",
    "         AND split_part(rc.ip_address::text, '.', 2)::int BETWEEN 0 AND 255\n",
    "         AND split_part(rc.ip_address::text, '.', 3)::int BETWEEN 0 AND 255\n",
    "         AND split_part(rc.ip_address::text, '.', 4)::int BETWEEN 0 AND 255\n",
    "        THEN rc.ip_address::inet\n",
    "        ELSE NULL\n",
    "    END                                  AS ip_inet,\n",
    "\n",
    "    -- Device normalized (lower + trim)\n",
    "    NULLIF(trim(lower(rc.device_type)), '') AS device_type_norm,\n",
    "\n",
    "    -- Timestamps (cast) + quality flags\n",
    "    rc.click_time::timestamp             AS click_ts,\n",
    "    (rc.click_time::timestamp > NOW() + INTERVAL '1 day')  AS future_time_flag,\n",
    "    (rc.click_time::timestamp < NOW() - INTERVAL '10 years') AS ancient_time_flag,\n",
    "\n",
    "    -- Referrer domain via regex\n",
    "    lower(COALESCE(substring(rc.referrer_url from '^(?:https?://)?(?:www\\\\.)?([^/:?#]+)'), '')) AS ref_domain,\n",
    "\n",
    "    -- Bot UA flag\n",
    "    (rc.user_agent ~* '(bot|spider|crawler|curl|wget)') AS bot_ua_flag,\n",
    "\n",
    "    -- Original fields for traceability\n",
    "    rc.referrer_url,\n",
    "    rc.user_agent,\n",
    "\n",
    "    -- Quality flags (missing device, invalid IP)\n",
    "    (rc.device_type IS NULL OR trim(rc.device_type) = '') AS missing_device_flag,\n",
    "    (NOT (\n",
    "        rc.ip_address::text ~ '^(?:\\\\d{1,3}\\\\.){3}\\\\d{1,3}$'\n",
    "        AND split_part(rc.ip_address::text, '.', 1)::int BETWEEN 0 AND 255\n",
    "        AND split_part(rc.ip_address::text, '.', 2)::int BETWEEN 0 AND 255\n",
    "        AND split_part(rc.ip_address::text, '.', 3)::int BETWEEN 0 AND 255\n",
    "        AND split_part(rc.ip_address::text, '.', 4)::int BETWEEN 0 AND 255\n",
    "    )) AS invalid_ip_flag\n",
    "FROM raw_clicks rc\n",
    "WHERE rc.click_time IS NOT NULL;\n",
    "\n",
    "-- Helpful indexes\n",
    "CREATE INDEX IF NOT EXISTS idx_stage_clean_time ON staging_clicks_clean(click_ts);\n",
    "CREATE INDEX IF NOT EXISTS idx_stage_clean_ip   ON staging_clicks_clean(ip_inet);\n",
    "CREATE INDEX IF NOT EXISTS idx_stage_clean_ad   ON staging_clicks_clean(ad_id);\n",
    "\"\"\"\n",
    "run_sql(sql_staging_clean)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    n = conn.execute(text(\"SELECT COUNT(*) FROM staging_clicks_clean\")).scalar()\n",
    "print(\"staging_clicks_clean rows:\", n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Deduplicate near-duplicate clicks into staging_clicks_dedup\n",
    "# Strategy: keep 1 row per (ad_id, ip_inet, second(click_ts)) using ROW_NUMBER window\n",
    "\n",
    "sql_dedup = \"\"\"\n",
    "DROP TABLE IF EXISTS staging_clicks_dedup;\n",
    "CREATE TABLE staging_clicks_dedup AS\n",
    "WITH ranked AS (\n",
    "  SELECT s.*,\n",
    "         ROW_NUMBER() OVER (\n",
    "           PARTITION BY s.ad_id, s.ip_inet, date_trunc('second', s.click_ts)\n",
    "           ORDER BY s.click_ts, s.ref_domain\n",
    "         ) AS rn\n",
    "  FROM staging_clicks_clean s\n",
    ")\n",
    "SELECT * FROM ranked WHERE rn = 1;\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_stage_dedup_keys ON staging_clicks_dedup(ad_id, ip_inet, click_ts);\n",
    "\"\"\"\n",
    "run_sql(sql_dedup)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    before = conn.execute(text(\"SELECT COUNT(*) FROM staging_clicks_clean\")).scalar()\n",
    "    after  = conn.execute(text(\"SELECT COUNT(*) FROM staging_clicks_dedup\")).scalar()\n",
    "print(f\"Dedup done: {before:,} → {after:,} rows (removed {before-after:,})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd09f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Clean emails from ad_connections using Python regex\n",
    "# - Handles formats like \"john (at) gmail.com\", \"john[at]gmail.com\", extra spaces\n",
    "# - Lowercases, strips, removes illegal chars\n",
    "# - Invalid emails become None\n",
    "# Writes to: ad_connections_clean (replace each run)\n",
    "\n",
    "def clean_email(email):\n",
    "    if not isinstance(email, str):\n",
    "        return None\n",
    "    email = email.strip().lower()\n",
    "    # common obfuscations\n",
    "    email = re.sub(r\"\\\\s*\\\\(at\\\\)\\\\s*|\\\\s*\\\\[at\\\\]\\\\s*\", \"@\", email)\n",
    "    email = re.sub(r\"\\\\s*@\\\\s*\", \"@\", email)\n",
    "    # drop weird chars (keep alnum, @ . _ -)\n",
    "    email = re.sub(r\"[^a-z0-9@._-]+\", \"\", email)\n",
    "    # simple validation\n",
    "    if not re.match(r\"^[a-z0-9._%-]+@[a-z0-9.-]+\\\\.[a-z]{2,}$\", email):\n",
    "        return None\n",
    "    return email\n",
    "\n",
    "df_conn = pd.read_sql(\"SELECT * FROM ad_connections\", engine)\n",
    "df_conn[\"email_clean\"] = df_conn[\"email\"].apply(clean_email)\n",
    "df_conn[\"invalid_email_flag\"] = df_conn[\"email_clean\"].isna()\n",
    "\n",
    "# Write cleaned table\n",
    "df_conn.to_sql(\"ad_connections_clean\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\n",
    "    \"ad_connections_clean written.\",\n",
    "    \"Invalid emails:\", int(df_conn[\"invalid_email_flag\"].sum()),\n",
    "    \" / total:\", len(df_conn)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74084272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Normalize ad categories using canonical set + fuzzy fallback\n",
    "# Canonical categories for this project:\n",
    "CANONICAL_CATS = [\"retail\", \"tech\", \"finance\", \"travel\"]\n",
    "\n",
    "def normalize_category(value: str) -> str:\n",
    "    if not isinstance(value, str) or not value.strip():\n",
    "        return None\n",
    "    raw = value.strip().lower()\n",
    "    # exact match\n",
    "    if raw in CANONICAL_CATS:\n",
    "        return raw\n",
    "    # fuzzy fallback using difflib\n",
    "    hit = get_close_matches(raw, CANONICAL_CATS, n=1, cutoff=0.7)\n",
    "    return hit[0] if hit else raw  # if no good match, keep original (lowercased)\n",
    "\n",
    "df_ads = pd.read_sql(\"SELECT * FROM ads\", engine)\n",
    "df_ads[\"category_norm\"] = df_ads[\"category\"].apply(normalize_category)\n",
    "\n",
    "# Optional: map obvious typos to canonical\n",
    "MAP_OVERRIDES = {\n",
    "    \"moblie\": \"mobile\",  # (example if you use it elsewhere)\n",
    "    \"retal\": \"retail\",\n",
    "}\n",
    "df_ads[\"category_norm\"] = df_ads[\"category_norm\"].replace(MAP_OVERRIDES)\n",
    "\n",
    "df_ads.to_sql(\"ads_clean\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"ads_clean written. Category distribution:\")\n",
    "print(df_ads[\"category_norm\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Data-quality dashboard: basic KPIs you can show in README\n",
    "sql_kpis = \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    COUNT(*)                        AS total,\n",
    "    SUM(invalid_ip_flag::int)       AS invalid_ip,\n",
    "    SUM(missing_device_flag::int)   AS missing_device,\n",
    "    SUM(future_time_flag::int)      AS future_time,\n",
    "    SUM(ancient_time_flag::int)     AS ancient_time,\n",
    "    SUM(bot_ua_flag::int)           AS bot_ua\n",
    "  FROM staging_clicks_clean\n",
    "),\n",
    "dedup AS (\n",
    "  SELECT (SELECT COUNT(*) FROM staging_clicks_clean)  AS n_clean,\n",
    "         (SELECT COUNT(*) FROM staging_clicks_dedup)  AS n_dedup\n",
    ")\n",
    "SELECT\n",
    "  base.total,\n",
    "  base.invalid_ip,\n",
    "  base.missing_device,\n",
    "  base.future_time,\n",
    "  base.ancient_time,\n",
    "  base.bot_ua,\n",
    "  dedup.n_clean,\n",
    "  dedup.n_dedup,\n",
    "  (dedup.n_clean - dedup.n_dedup) AS removed_duplicates\n",
    "FROM base, dedup;\n",
    "\"\"\"\n",
    "kpis = pd.read_sql(sql_kpis, engine)\n",
    "kpis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9304a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Optional: export small snapshots for the repo (helps recruiters view results without DB)\n",
    "# Note: keep samples small to avoid bloating the repo\n",
    "\n",
    "sample_clean   = pd.read_sql(\"SELECT * FROM staging_clicks_clean LIMIT 1000\", engine)\n",
    "sample_dedup   = pd.read_sql(\"SELECT * FROM staging_clicks_dedup LIMIT 1000\", engine)\n",
    "sample_emails  = pd.read_sql(\"SELECT * FROM ad_connections_clean LIMIT 1000\", engine)\n",
    "sample_ads     = pd.read_sql(\"SELECT * FROM ads_clean\", engine)\n",
    "\n",
    "os.makedirs(\"../reports\", exist_ok=True)\n",
    "sample_clean.to_csv(\"../reports/sample_staging_clicks_clean.csv\", index=False)\n",
    "sample_dedup.to_csv(\"../reports/sample_staging_clicks_dedup.csv\", index=False)\n",
    "sample_emails.to_csv(\"../reports/sample_ad_connections_clean.csv\", index=False)\n",
    "sample_ads.to_csv(\"../reports/ads_clean.csv\", index=False)\n",
    "\n",
    "print(\"Snapshots exported to /reports.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c143a23",
   "metadata": {},
   "source": [
    "## ✅ Silver Layer complete\n",
    "\n",
    "- Built: `staging_clicks_clean`, `staging_clicks_dedup`, `ad_connections_clean`, `ads_clean`\n",
    "- Applied:\n",
    "  - Regex validation for IPv4, bot user-agents\n",
    "  - Domain extraction from referrers + UTM noise handling (ready for removal upstream)\n",
    "  - Timestamp casting + future/ancient flags\n",
    "  - Device normalization & missing flags\n",
    "  - Deduplication using window functions\n",
    "  - Email cleaning with Python regex\n",
    "  - Category normalization with fuzzy matching\n",
    "\n",
    "**Next:** Feature engineering (`fraud_signals`) and modeling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

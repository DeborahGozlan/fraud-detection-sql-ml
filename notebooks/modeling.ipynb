{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c19b5c",
   "metadata": {},
   "source": [
    "# Modeling â€” Ad Fraud Detection\n",
    "\n",
    "**Goal:** Train baseline models on the Gold table `fraud_signals`.\n",
    "\n",
    "**Weâ€™ll do:**\n",
    "1) Load features from PostgreSQL (`fraud_signals`)\n",
    "2) Build a **label** by joining `ad_performance.fraud` on `(date, ad_id)`\n",
    "3) Split by time (train vs. recent validation)\n",
    "4) **Supervised baseline:** LightGBM (class_weight balanced)\n",
    "5) **Unsupervised baseline:** IsolationForest (rank anomalies)\n",
    "6) Evaluate with ROC AUC, PR AUC, precision/recall at top-K, and feature importance\n",
    "7) Save artifacts (CSV + model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3be27184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to: PostgreSQL 17.5 (Postgres.app) on aarch64-apple-darwin23.6.0, compiled by Apple clang version 15.0.0 (clang-1500.3.9.4), 64-bit\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Import core libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ðŸ“‚ Load environment variables (DB credentials)\n",
    "load_dotenv()\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\") or os.getenv(\"PGUSER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\") or os.getenv(\"PGHOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\") or os.getenv(\"PGPORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or os.getenv(\"PGDATABASE\")\n",
    "\n",
    "# Create engine for PostgreSQL connection\n",
    "if DB_PASSWORD:\n",
    "    DATABASE_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "else:\n",
    "    DATABASE_URL = f\"postgresql+psycopg2://{DB_USER}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Test connection\n",
    "with engine.connect() as conn:\n",
    "    version = conn.execute(text(\"SELECT version()\")).scalar()\n",
    "print(\"âœ… Connected to:\", version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "104b617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== clean.clicks ==\n",
      "        n                      min_t                      max_t\n",
      "0  520000 2015-08-13 01:48:29.530750 2025-08-17 02:03:05.037790\n",
      "\n",
      "== clean.ad_performance ==\n",
      "      n       min_d       max_d\n",
      "0  1200  2025-07-08  2025-08-10\n",
      "\n",
      "== clean.connections ==\n",
      "      n\n",
      "0  2000\n",
      "\n",
      "== Exemple clicks ==\n",
      "   ad_id                 click_time\n",
      "0  AD005 2025-08-17 02:03:05.037790\n",
      "1  AD002 2025-08-17 02:03:05.037790\n",
      "2  AD003 2025-08-17 02:03:05.037790\n",
      "3  AD003 2025-08-17 02:03:05.037790\n",
      "4  AD008 2025-08-17 02:03:05.037790\n",
      "\n",
      "== Exemple perf ==\n",
      "   ad_id        date  clicks  conversions\n",
      "0  AD004  2025-08-10     315          211\n",
      "1  AD002  2025-08-10    2932         1012\n",
      "2  AD001  2025-08-10     666           94\n",
      "3  AD003  2025-08-10    1173         1018\n",
      "4  AD005  2025-08-10     113           10\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check to avoid empty joins later\n",
    "print(\"== clean.clicks ==\")\n",
    "print(pd.read_sql(\"SELECT COUNT(*) AS n, MIN(click_time) min_t, MAX(click_time) max_t FROM clean.clicks\", engine))\n",
    "\n",
    "print(\"\\n== clean.ad_performance ==\")\n",
    "print(pd.read_sql(\"SELECT COUNT(*) AS n, MIN(date) min_d, MAX(date) max_d FROM clean.ad_performance\", engine))\n",
    "\n",
    "print(\"\\n== clean.connections ==\")\n",
    "print(pd.read_sql(\"SELECT COUNT(*) AS n FROM clean.connections\", engine))\n",
    "\n",
    "print(\"\\n== Exemple clicks ==\")\n",
    "print(pd.read_sql(\"SELECT ad_id, click_time FROM clean.clicks ORDER BY click_time DESC LIMIT 5\", engine))\n",
    "\n",
    "print(\"\\n== Exemple perf ==\")\n",
    "print(pd.read_sql(\"SELECT ad_id, date, clicks, conversions FROM clean.ad_performance ORDER BY date DESC LIMIT 5\", engine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65c94c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== clean.clicks ==\n",
      "        n                      min_t                      max_t\n",
      "0  520000 2015-08-13 01:48:29.530750 2025-08-17 02:03:05.037790\n",
      "\n",
      "== clean.ad_performance ==\n",
      "      n       min_d       max_d\n",
      "0  1200  2025-07-08  2025-08-10\n",
      "\n",
      "== clean.connections ==\n",
      "      n\n",
      "0  2000\n",
      "\n",
      "== Exemple clicks ==\n",
      "   ad_id                 click_time\n",
      "0  AD005 2025-08-17 02:03:05.037790\n",
      "1  AD002 2025-08-17 02:03:05.037790\n",
      "2  AD003 2025-08-17 02:03:05.037790\n",
      "3  AD003 2025-08-17 02:03:05.037790\n",
      "4  AD008 2025-08-17 02:03:05.037790\n",
      "\n",
      "== Exemple perf ==\n",
      "   ad_id        date  clicks  conversions\n",
      "0  AD004  2025-08-10     315          211\n",
      "1  AD002  2025-08-10    2932         1012\n",
      "2  AD001  2025-08-10     666           94\n",
      "3  AD003  2025-08-10    1173         1018\n",
      "4  AD005  2025-08-10     113           10\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check to avoid empty joins later\n",
    "print(\"== clean.clicks ==\")\n",
    "print(pd.read_sql(\"SELECT COUNT(*) AS n, MIN(click_time) min_t, MAX(click_time) max_t FROM clean.clicks\", engine))\n",
    "\n",
    "print(\"\\n== clean.ad_performance ==\")\n",
    "print(pd.read_sql(\"SELECT COUNT(*) AS n, MIN(date) min_d, MAX(date) max_d FROM clean.ad_performance\", engine))\n",
    "\n",
    "print(\"\\n== clean.connections ==\")\n",
    "print(pd.read_sql(\"SELECT COUNT(*) AS n FROM clean.connections\", engine))\n",
    "\n",
    "print(\"\\n== Exemple clicks ==\")\n",
    "print(pd.read_sql(\"SELECT ad_id, click_time FROM clean.clicks ORDER BY click_time DESC LIMIT 5\", engine))\n",
    "\n",
    "print(\"\\n== Exemple perf ==\")\n",
    "print(pd.read_sql(\"SELECT ad_id, date, clicks, conversions FROM clean.ad_performance ORDER BY date DESC LIMIT 5\", engine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a7805f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rows fetched: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>clicks_day</th>\n",
       "      <th>impressions</th>\n",
       "      <th>perf_clicks</th>\n",
       "      <th>conversions</th>\n",
       "      <th>ctr</th>\n",
       "      <th>conversion_rate</th>\n",
       "      <th>bounce_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD001</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>16682</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD002</td>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>320</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD001</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>14761</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD003</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>14826</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD010</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>2607</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad_id  as_of_date  clicks_day impressions perf_clicks conversions   ctr  \\\n",
       "0  AD001  2017-11-07       16682        None        None        None  None   \n",
       "1  AD002  2025-08-17         320        None        None        None  None   \n",
       "2  AD001  2017-11-09       14761        None        None        None  None   \n",
       "3  AD003  2017-11-09       14826        None        None        None  None   \n",
       "4  AD010  2017-11-06        2607        None        None        None  None   \n",
       "\n",
       "  conversion_rate bounce_rate  \n",
       "0            None        None  \n",
       "1            None        None  \n",
       "2            None        None  \n",
       "3            None        None  \n",
       "4            None        None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH clicks_day AS (\n",
    "  SELECT \n",
    "    ad_id,\n",
    "    (click_time::date) AS as_of_date,\n",
    "    COUNT(*) AS clicks_day\n",
    "  FROM clean.clicks\n",
    "  GROUP BY ad_id, as_of_date\n",
    ")\n",
    "SELECT \n",
    "  cd.ad_id,\n",
    "  cd.as_of_date,\n",
    "  cd.clicks_day,\n",
    "  ap.impressions,\n",
    "  ap.clicks AS perf_clicks,\n",
    "  ap.conversions,\n",
    "  ap.ctr,\n",
    "  ap.conversion_rate,\n",
    "  ap.bounce_rate\n",
    "FROM clicks_day cd\n",
    "LEFT JOIN clean.ad_performance ap\n",
    "  ON ap.ad_id = cd.ad_id\n",
    " AND ap.date  = cd.as_of_date\n",
    "LIMIT 5000;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, engine)\n",
    "print(\"âœ… Rows fetched:\", df.shape[0])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9345f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>clicks_day</th>\n",
       "      <th>impressions</th>\n",
       "      <th>perf_clicks</th>\n",
       "      <th>conversions</th>\n",
       "      <th>ctr</th>\n",
       "      <th>conversion_rate</th>\n",
       "      <th>bounce_rate</th>\n",
       "      <th>fraud</th>\n",
       "      <th>rn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD001</td>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>161</td>\n",
       "      <td>2405</td>\n",
       "      <td>1358</td>\n",
       "      <td>243</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD001</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>2468</td>\n",
       "      <td>2405</td>\n",
       "      <td>1358</td>\n",
       "      <td>243</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD001</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>16682</td>\n",
       "      <td>2405</td>\n",
       "      <td>1358</td>\n",
       "      <td>243</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD001</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>17369</td>\n",
       "      <td>2405</td>\n",
       "      <td>1358</td>\n",
       "      <td>243</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD001</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>14761</td>\n",
       "      <td>2405</td>\n",
       "      <td>1358</td>\n",
       "      <td>243</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad_id  as_of_date  clicks_day  impressions  perf_clicks  conversions  \\\n",
       "0  AD001  2015-08-13         161         2405         1358          243   \n",
       "1  AD001  2017-11-06        2468         2405         1358          243   \n",
       "2  AD001  2017-11-07       16682         2405         1358          243   \n",
       "3  AD001  2017-11-08       17369         2405         1358          243   \n",
       "4  AD001  2017-11-09       14761         2405         1358          243   \n",
       "\n",
       "      ctr  conversion_rate  bounce_rate  fraud  rn  \n",
       "0  0.5647           0.1789        0.117   True   1  \n",
       "1  0.5647           0.1789        0.117   True   1  \n",
       "2  0.5647           0.1789        0.117   True   1  \n",
       "3  0.5647           0.1789        0.117   True   1  \n",
       "4  0.5647           0.1789        0.117   True   1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_sql = \"\"\"\n",
    "WITH clicks_day AS (\n",
    "  SELECT ad_id, (click_time::date) AS as_of_date, COUNT(*) AS clicks_day\n",
    "  FROM clean.clicks\n",
    "  GROUP BY ad_id, as_of_date\n",
    "),\n",
    "joined AS (\n",
    "  SELECT\n",
    "    cd.*,\n",
    "    ap.impressions, ap.clicks AS perf_clicks, ap.conversions, ap.ctr, ap.conversion_rate, ap.bounce_rate,\n",
    "    ap.fraud,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY cd.ad_id, cd.as_of_date\n",
    "      ORDER BY ABS(ap.date - cd.as_of_date)\n",
    "    ) AS rn\n",
    "  FROM clicks_day cd\n",
    "  LEFT JOIN clean.ad_performance ap\n",
    "    ON ap.ad_id = cd.ad_id\n",
    ")\n",
    "SELECT *\n",
    "FROM joined\n",
    "WHERE rn = 1\n",
    "LIMIT 50000;  -- garde raisonnable pour ton laptop\n",
    "\"\"\"\n",
    "df = pd.read_sql(nearest_sql, engine)\n",
    "print(\"Rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e387ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label distribution -> positives: 64 / 240\n",
      "Numeric features: ['clicks_day', 'impressions', 'perf_clicks', 'conversions', 'ctr', 'conversion_rate', 'bounce_rate']\n",
      "Categorical: ['category_norm']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>label</th>\n",
       "      <th>clicks_day</th>\n",
       "      <th>impressions</th>\n",
       "      <th>perf_clicks</th>\n",
       "      <th>conversions</th>\n",
       "      <th>ctr</th>\n",
       "      <th>conversion_rate</th>\n",
       "      <th>bounce_rate</th>\n",
       "      <th>category_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>AD001</td>\n",
       "      <td>1</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>AD001</td>\n",
       "      <td>1</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>AD001</td>\n",
       "      <td>1</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   as_of_date  ad_id  label  clicks_day  impressions  perf_clicks  \\\n",
       "0  2015-08-13  AD001      1       161.0       2405.0       1358.0   \n",
       "1  2015-08-13  AD001      1       161.0       2405.0       1358.0   \n",
       "2  2015-08-13  AD001      1       161.0       2405.0       1358.0   \n",
       "\n",
       "   conversions     ctr  conversion_rate  bounce_rate category_norm  \n",
       "0        243.0  0.5647           0.1789        0.117          tech  \n",
       "1        243.0  0.5647           0.1789        0.117       finance  \n",
       "2        243.0  0.5647           0.1789        0.117       finance  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 6.1) CrÃ©er / valider le label binaire\n",
    "# On privilÃ©gie la colonne 'fraud' si elle existe dans df (provenant de ad_performance.fraud).\n",
    "if \"label\" not in df.columns:\n",
    "    if \"fraud\" in df.columns:\n",
    "        df[\"label\"] = df[\"fraud\"].fillna(0).astype(int)\n",
    "    else:\n",
    "        # Fallback simple & explicable si 'fraud' indisponible :\n",
    "        # \"suspect\" si beaucoup de clics et 0 conversions\n",
    "        df[\"label\"] = ((df.get(\"clicks_day\", 0) >= 50) & (df.get(\"conversions\", 0) == 0)).astype(int)\n",
    "\n",
    "# 6.2) Liste de colonnes numÃ©riques candidates (on ne garde que celles prÃ©sentes)\n",
    "candidate_num = [\n",
    "    \"clicks_day\", \"impressions\", \"perf_clicks\", \"conversions\",\n",
    "    \"ctr\", \"conversion_rate\", \"bounce_rate\"\n",
    "]\n",
    "num_cols = [c for c in candidate_num if c in df.columns]\n",
    "\n",
    "# 6.3) Categorical â€” on utilise la catÃ©gorie dâ€™annonce normalisÃ©e\n",
    "# (si elle nâ€™existe pas encore, on la rÃ©cupÃ¨re depuis clean.ads)\n",
    "if \"category_norm\" not in df.columns:\n",
    "    ads = pd.read_sql(\"SELECT ad_id, category FROM clean.ads;\", engine)\n",
    "    ads[\"category_norm\"] = (\n",
    "        ads[\"category\"].fillna(\"unknown\").astype(str).str.strip()\n",
    "           .str.lower().str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    )\n",
    "    df = df.merge(ads[[\"ad_id\", \"category_norm\"]], on=\"ad_id\", how=\"left\")\n",
    "\n",
    "df[\"category_norm\"] = df[\"category_norm\"].fillna(\"unknown\").astype(str)\n",
    "cat_cols = [\"category_norm\"]\n",
    "\n",
    "# 6.4) Nettoyage NA\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].astype(float).fillna(0.0)\n",
    "\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "# 6.5) Colonnes mÃ©ta (optionnelles)\n",
    "meta_cols = [c for c in [\"as_of_date\",\"ad_id\",\"ip_address\"] if c in df.columns]\n",
    "\n",
    "print(\"âœ… Label distribution -> positives:\", int(df[\"label\"].sum()), \"/\", len(df))\n",
    "print(\"Numeric features:\", num_cols)\n",
    "print(\"Categorical:\", cat_cols)\n",
    "df[ (meta_cols + [\"label\"] + num_cols + cat_cols) ].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abbdaa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (180, 8)  Test size: (60, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 7.1) Jeu de donnÃ©es X / y\n",
    "feature_cols = num_cols + cat_cols\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# 7.2) PrÃ©processeur : OneHot sur la catÃ©gorie, passthrough sur numÃ©riques\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# 7.3) Deux pipelines : LogReg (baseline) et RandomForest (non linÃ©aire)\n",
    "logreg_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=200, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 7.4) Split (stratifiÃ©)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78fa8b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deborahgozlan/Documents/fraud_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 200 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=200).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogisticRegression ===\n",
      "ROC-AUC: 0.8082386363636365\n",
      "PR-AUC : 0.48108477227163293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.84        44\n",
      "           1       0.56      0.88      0.68        16\n",
      "\n",
      "    accuracy                           0.78        60\n",
      "   macro avg       0.75      0.81      0.76        60\n",
      "weighted avg       0.84      0.78      0.79        60\n",
      "\n",
      "Confusion matrix:\n",
      " [[33, 11], [2, 14]]\n",
      "\n",
      "=== RandomForest ===\n",
      "ROC-AUC: 1.0\n",
      "PR-AUC : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        44\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "Confusion matrix:\n",
      " [[44, 0], [0, 16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    # ProbabilitÃ© / score\n",
    "    if hasattr(model.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_te)[:, 1]\n",
    "    else:\n",
    "        # fallback pour modÃ¨les sans predict_proba\n",
    "        y_proba = model.decision_function(X_te) if hasattr(model, \"decision_function\") else model.predict(X_te)\n",
    "\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"roc_auc\": roc_auc_score(y_te, y_proba) if len(np.unique(y_te))>1 else None,\n",
    "        \"pr_auc\": average_precision_score(y_te, y_proba) if len(np.unique(y_te))>1 else None,\n",
    "        \"report\": classification_report(y_te, y_pred, output_dict=True),\n",
    "        \"confusion_matrix\": confusion_matrix(y_te, y_pred).tolist()\n",
    "    }\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"ROC-AUC:\", metrics[\"roc_auc\"])\n",
    "    print(\"PR-AUC :\", metrics[\"pr_auc\"])\n",
    "    print(classification_report(y_te, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", metrics[\"confusion_matrix\"])\n",
    "    return metrics, y_proba, y_pred\n",
    "\n",
    "metrics_logreg, proba_logreg, pred_logreg = evaluate_model(\"LogisticRegression\", logreg_clf, X_train, y_train, X_test, y_test)\n",
    "metrics_rf,     proba_rf,     pred_rf     = evaluate_model(\"RandomForest\",       rf_clf,     X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "479c8642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved models to models/*.joblib and metrics to reports/*.json\n"
     ]
    }
   ],
   "source": [
    "import json, joblib\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "Path(\"reports\").mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(logreg_clf, \"models/logreg_pipeline.joblib\")\n",
    "joblib.dump(rf_clf,     \"models/rf_pipeline.joblib\")\n",
    "\n",
    "with open(\"reports/logreg_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics_logreg, f, indent=2)\n",
    "with open(\"reports/rf_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics_rf, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved models to models/*.joblib and metrics to reports/*.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60e35746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>impressions</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.029861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bounce_rate</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctr</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clicks_day</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conversions</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perf_clicks</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conversion_rate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>category_norm</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance_mean  importance_std\n",
       "1      impressions            0.055        0.029861\n",
       "6      bounce_rate            0.015        0.008975\n",
       "4              ctr            0.010        0.008165\n",
       "0       clicks_day            0.000        0.000000\n",
       "3      conversions            0.000        0.000000\n",
       "2      perf_clicks            0.000        0.000000\n",
       "5  conversion_rate            0.000        0.000000\n",
       "7    category_norm            0.000        0.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permutation importance on the SAME input columns used to train the pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# use the same features you trained on\n",
    "feature_cols = num_cols + cat_cols\n",
    "\n",
    "# sample to keep it light\n",
    "rng = np.random.RandomState(42)\n",
    "sample_idx = rng.choice(len(X_test), size=min(2000, len(X_test)), replace=False)\n",
    "X_te_sample = X_test.iloc[sample_idx]\n",
    "y_te_sample = y_test[sample_idx]\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "result = permutation_importance(\n",
    "    rf_clf, X_te_sample, y_te_sample,\n",
    "    n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "imp = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "imp.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4be35541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top anomalies:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>clicks_day</th>\n",
       "      <th>impressions</th>\n",
       "      <th>perf_clicks</th>\n",
       "      <th>conversions</th>\n",
       "      <th>ctr</th>\n",
       "      <th>conversion_rate</th>\n",
       "      <th>bounce_rate</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD009</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4026.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.044317</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD009</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4026.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.044317</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD009</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4026.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.044317</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD009</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4026.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.044317</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD001</td>\n",
       "      <td>303.0</td>\n",
       "      <td>4621.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.6118</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD001</td>\n",
       "      <td>303.0</td>\n",
       "      <td>4621.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.6118</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD001</td>\n",
       "      <td>303.0</td>\n",
       "      <td>4621.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.6118</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD001</td>\n",
       "      <td>303.0</td>\n",
       "      <td>4621.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.6118</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD008</td>\n",
       "      <td>297.0</td>\n",
       "      <td>4092.0</td>\n",
       "      <td>2951.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>AD008</td>\n",
       "      <td>297.0</td>\n",
       "      <td>4092.0</td>\n",
       "      <td>2951.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     as_of_date  ad_id  clicks_day  impressions  perf_clicks  conversions  \\\n",
       "212  2025-08-17  AD009       327.0       4026.0       3080.0       3067.0   \n",
       "213  2025-08-17  AD009       327.0       4026.0       3080.0       3067.0   \n",
       "214  2025-08-17  AD009       327.0       4026.0       3080.0       3067.0   \n",
       "215  2025-08-17  AD009       327.0       4026.0       3080.0       3067.0   \n",
       "20   2025-08-17  AD001       303.0       4621.0       2457.0       1965.0   \n",
       "21   2025-08-17  AD001       303.0       4621.0       2457.0       1965.0   \n",
       "22   2025-08-17  AD001       303.0       4621.0       2457.0       1965.0   \n",
       "23   2025-08-17  AD001       303.0       4621.0       2457.0       1965.0   \n",
       "188  2025-08-17  AD008       297.0       4092.0       2951.0       2860.0   \n",
       "189  2025-08-17  AD008       297.0       4092.0       2951.0       2860.0   \n",
       "\n",
       "        ctr  conversion_rate  bounce_rate  anomaly_score  is_outlier  \n",
       "212  0.7650           0.9958       0.9172       0.044317        True  \n",
       "213  0.7650           0.9958       0.9172       0.044317        True  \n",
       "214  0.7650           0.9958       0.9172       0.044317        True  \n",
       "215  0.7650           0.9958       0.9172       0.044317        True  \n",
       "20   0.5317           0.7998       0.6118      -0.000000       False  \n",
       "21   0.5317           0.7998       0.6118      -0.000000       False  \n",
       "22   0.5317           0.7998       0.6118      -0.000000       False  \n",
       "23   0.5317           0.7998       0.6118      -0.000000       False  \n",
       "188  0.7212           0.9692       0.2581      -0.008061       False  \n",
       "189  0.7212           0.9692       0.2581      -0.008061       False  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# On prend uniquement les features numÃ©riques (zÃ©ro NA)\n",
    "X_num = df[num_cols].fillna(0.0).astype(float)\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=200, contamination=0.02, random_state=42, n_jobs=-1\n",
    ")\n",
    "iso.fit(X_num)\n",
    "anomaly_score = -iso.decision_function(X_num)  # plus grand => plus anormal\n",
    "is_outlier = iso.predict(X_num) == -1\n",
    "\n",
    "anoms = df[meta_cols + num_cols].copy() if meta_cols else df[num_cols].copy()\n",
    "anoms[\"anomaly_score\"] = anomaly_score\n",
    "anoms[\"is_outlier\"] = is_outlier\n",
    "anoms_sorted = anoms.sort_values(\"anomaly_score\", ascending=False).head(20)\n",
    "\n",
    "print(\"Top anomalies:\")\n",
    "anoms_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0308c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved predictions to bi.model_predictions\n"
     ]
    }
   ],
   "source": [
    "# On stocke les rÃ©sultats test (RandomForest) pour Looker/Tableau\n",
    "pred_frame = df.loc[X_test.index, meta_cols].copy() if meta_cols else pd.DataFrame(index=X_test.index)\n",
    "pred_frame[\"label_true\"] = y_test\n",
    "pred_frame[\"proba_rf\"]   = proba_rf\n",
    "pred_frame[\"pred_rf\"]    = pred_rf\n",
    "\n",
    "# Sauvegarde en DB (schema bi)\n",
    "pred_frame.to_sql(\"model_predictions\", engine, schema=\"bi\", if_exists=\"replace\", index=False)\n",
    "print(\"âœ… Saved predictions to bi.model_predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5c5ab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold: 0.885000 | Precision: 1.000 | Recall: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "p, r, t = precision_recall_curve(y_test, proba_rf)\n",
    "\n",
    "# Align arrays: thresholds correspond to p[:-1], r[:-1]\n",
    "p_t = p[:-1]\n",
    "r_t = r[:-1]\n",
    "t_t = t\n",
    "\n",
    "# Target recall â‰¥ 0.80 (change if you want)\n",
    "TARGET_RECALL = 0.80\n",
    "mask = r_t >= TARGET_RECALL\n",
    "\n",
    "if mask.any():\n",
    "    # Among points meeting recall target, pick the one with best precision\n",
    "    best_local_idx = np.argmax(p_t[mask])\n",
    "    # Map back to global index\n",
    "    global_idx = np.flatnonzero(mask)[best_local_idx]\n",
    "    best_thr = t_t[global_idx]\n",
    "    print(f\"Chosen threshold: {best_thr:.6f} | Precision: {p_t[global_idx]:.3f} | Recall: {r_t[global_idx]:.3f}\")\n",
    "else:\n",
    "    # Fallback: maximize F1 across all thresholds\n",
    "    f1 = 2 * p_t * r_t / (p_t + r_t + 1e-9)\n",
    "    global_idx = np.nanargmax(f1)\n",
    "    best_thr = t_t[global_idx]\n",
    "    print(\n",
    "        \"No point reached the target recall; using F1-optimal threshold instead.\\n\"\n",
    "        f\"Chosen threshold: {best_thr:.6f} | Precision: {p_t[global_idx]:.3f} | Recall: {r_t[global_idx]:.3f} | F1: {f1[global_idx]:.3f}\"\n",
    "    )\n",
    "\n",
    "# If you want predictions at that threshold:\n",
    "y_pred_best = (proba_rf >= best_thr).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45fa1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "rf_cal = CalibratedClassifierCV(rf_clf, method=\"isotonic\", cv=3)\n",
    "rf_cal.fit(X_train, y_train)\n",
    "proba_rf_cal = rf_cal.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "321b6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {\n",
    "  \"clf__n_estimators\": [200, 300, 500],\n",
    "  \"clf__max_depth\": [None, 10, 20],\n",
    "  \"clf__min_samples_split\": [2, 5, 10],\n",
    "  \"clf__min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "search = RandomizedSearchCV(rf_clf, params, n_iter=12, scoring=\"average_precision\", n_jobs=-1, cv=3, random_state=42)\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a7403a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anoms_sorted.to_sql(\"anomalies_isoforest\", engine, schema=\"bi\", if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12e3a4",
   "metadata": {},
   "source": [
    "## âœ… Baselines complete\n",
    "\n",
    "**Supervised (LightGBM):**\n",
    "- Time-aware split (last 7 days as validation)\n",
    "- Balanced objective\n",
    "- Metrics: ROC AUC, PR AUC, threshold selection via PR curve\n",
    "- Permutation importance for interpretability\n",
    "- Artifacts saved (model + predictions)\n",
    "\n",
    "**Unsupervised (IsolationForest):**\n",
    "- Trained on clean TRAIN features\n",
    "- Ranked anomalies on validation\n",
    "- Useful when labels are scarce/noisy\n",
    "\n",
    "**Next ideas:**\n",
    "- Calibrate threshold for business target (e.g., 90% precision)\n",
    "- Add **graph features** (e.g., IP â†” ad community metrics)\n",
    "- Add **IP reputation / geo** enrichment\n",
    "- Try **XGBoost** and compare with LightGBM\n",
    "- Add **SHAP** for feature attribution (if needed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
